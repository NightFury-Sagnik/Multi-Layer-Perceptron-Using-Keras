{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>Z24</th>\n",
       "      <th>Z25</th>\n",
       "      <th>Z26</th>\n",
       "      <th>Z27</th>\n",
       "      <th>Z28</th>\n",
       "      <th>Z29</th>\n",
       "      <th>Z30</th>\n",
       "      <th>Z31</th>\n",
       "      <th>Z32</th>\n",
       "      <th>direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.189148</td>\n",
       "      <td>0.189148</td>\n",
       "      <td>0.189148</td>\n",
       "      <td>0.189148</td>\n",
       "      <td>0.177176</td>\n",
       "      <td>0.177176</td>\n",
       "      <td>0.174782</td>\n",
       "      <td>0.174782</td>\n",
       "      <td>0.174782</td>\n",
       "      <td>0.165205</td>\n",
       "      <td>...</td>\n",
       "      <td>9.768641</td>\n",
       "      <td>9.768641</td>\n",
       "      <td>9.581888</td>\n",
       "      <td>9.581888</td>\n",
       "      <td>9.581888</td>\n",
       "      <td>9.610620</td>\n",
       "      <td>9.610620</td>\n",
       "      <td>9.742304</td>\n",
       "      <td>9.742304</td>\n",
       "      <td>Above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.174782</td>\n",
       "      <td>0.174782</td>\n",
       "      <td>0.174782</td>\n",
       "      <td>0.122108</td>\n",
       "      <td>0.122108</td>\n",
       "      <td>0.122108</td>\n",
       "      <td>0.126897</td>\n",
       "      <td>0.126897</td>\n",
       "      <td>0.160416</td>\n",
       "      <td>0.160416</td>\n",
       "      <td>...</td>\n",
       "      <td>9.811738</td>\n",
       "      <td>9.811738</td>\n",
       "      <td>9.512454</td>\n",
       "      <td>9.512454</td>\n",
       "      <td>9.689631</td>\n",
       "      <td>9.689631</td>\n",
       "      <td>9.830893</td>\n",
       "      <td>9.830893</td>\n",
       "      <td>9.830893</td>\n",
       "      <td>Above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.256187</td>\n",
       "      <td>0.256187</td>\n",
       "      <td>0.256187</td>\n",
       "      <td>0.256187</td>\n",
       "      <td>0.284919</td>\n",
       "      <td>0.284919</td>\n",
       "      <td>0.260976</td>\n",
       "      <td>0.260976</td>\n",
       "      <td>0.268159</td>\n",
       "      <td>0.268159</td>\n",
       "      <td>...</td>\n",
       "      <td>9.773430</td>\n",
       "      <td>9.773430</td>\n",
       "      <td>9.392740</td>\n",
       "      <td>9.392740</td>\n",
       "      <td>9.792584</td>\n",
       "      <td>9.792584</td>\n",
       "      <td>9.792584</td>\n",
       "      <td>9.799767</td>\n",
       "      <td>9.799767</td>\n",
       "      <td>Above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.158022</td>\n",
       "      <td>0.158022</td>\n",
       "      <td>0.158022</td>\n",
       "      <td>0.088588</td>\n",
       "      <td>0.088588</td>\n",
       "      <td>0.088588</td>\n",
       "      <td>0.112531</td>\n",
       "      <td>0.112531</td>\n",
       "      <td>0.160416</td>\n",
       "      <td>0.160416</td>\n",
       "      <td>...</td>\n",
       "      <td>9.830893</td>\n",
       "      <td>9.830893</td>\n",
       "      <td>9.466963</td>\n",
       "      <td>9.466963</td>\n",
       "      <td>9.725544</td>\n",
       "      <td>9.725544</td>\n",
       "      <td>9.845258</td>\n",
       "      <td>9.845258</td>\n",
       "      <td>9.845258</td>\n",
       "      <td>Above</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.253793</td>\n",
       "      <td>0.253793</td>\n",
       "      <td>0.253793</td>\n",
       "      <td>0.232245</td>\n",
       "      <td>0.232245</td>\n",
       "      <td>0.232245</td>\n",
       "      <td>0.225062</td>\n",
       "      <td>0.225062</td>\n",
       "      <td>0.203513</td>\n",
       "      <td>0.203513</td>\n",
       "      <td>...</td>\n",
       "      <td>9.419077</td>\n",
       "      <td>9.419077</td>\n",
       "      <td>9.720756</td>\n",
       "      <td>9.720756</td>\n",
       "      <td>9.744699</td>\n",
       "      <td>9.744699</td>\n",
       "      <td>9.502876</td>\n",
       "      <td>9.502876</td>\n",
       "      <td>9.502876</td>\n",
       "      <td>Above</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1        X2        X3        X4        X5        X6        X7  \\\n",
       "0  0.189148  0.189148  0.189148  0.189148  0.177176  0.177176  0.174782   \n",
       "1  0.174782  0.174782  0.174782  0.122108  0.122108  0.122108  0.126897   \n",
       "2  0.256187  0.256187  0.256187  0.256187  0.284919  0.284919  0.260976   \n",
       "3  0.158022  0.158022  0.158022  0.088588  0.088588  0.088588  0.112531   \n",
       "4  0.253793  0.253793  0.253793  0.232245  0.232245  0.232245  0.225062   \n",
       "\n",
       "         X8        X9       X10  ...       Z24       Z25       Z26       Z27  \\\n",
       "0  0.174782  0.174782  0.165205  ...  9.768641  9.768641  9.581888  9.581888   \n",
       "1  0.126897  0.160416  0.160416  ...  9.811738  9.811738  9.512454  9.512454   \n",
       "2  0.260976  0.268159  0.268159  ...  9.773430  9.773430  9.392740  9.392740   \n",
       "3  0.112531  0.160416  0.160416  ...  9.830893  9.830893  9.466963  9.466963   \n",
       "4  0.225062  0.203513  0.203513  ...  9.419077  9.419077  9.720756  9.720756   \n",
       "\n",
       "        Z28       Z29       Z30       Z31       Z32  direction  \n",
       "0  9.581888  9.610620  9.610620  9.742304  9.742304      Above  \n",
       "1  9.689631  9.689631  9.830893  9.830893  9.830893      Above  \n",
       "2  9.792584  9.792584  9.792584  9.799767  9.799767      Above  \n",
       "3  9.725544  9.725544  9.845258  9.845258  9.845258      Above  \n",
       "4  9.744699  9.744699  9.502876  9.502876  9.502876      Above  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Training.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(813, 97)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8', 'X9', 'X10', 'X11',\n",
       "       'X12', 'X13', 'X14', 'X15', 'X16', 'X17', 'X18', 'X19', 'X20', 'X21',\n",
       "       'X22', 'X23', 'X24', 'X25', 'X26', 'X27', 'X28', 'X29', 'X30', 'X31',\n",
       "       'X32', 'Y1', 'Y2', 'Y3', 'Y4', 'Y5', 'Y6', 'Y7', 'Y8', 'Y9', 'Y10',\n",
       "       'Y11', 'Y12', 'Y13', 'Y14', 'Y15', 'Y16', 'Y17', 'Y18', 'Y19', 'Y20',\n",
       "       'Y21', 'Y22', 'Y23', 'Y24', 'Y25', 'Y26', 'Y27', 'Y28', 'Y29', 'Y30',\n",
       "       'Y31', 'Y32', 'Z1', 'Z2', 'Z3', 'Z4', 'Z5', 'Z6', 'Z7', 'Z8', 'Z9',\n",
       "       'Z10', 'Z11', 'Z12', 'Z13', 'Z14', 'Z15', 'Z16', 'Z17', 'Z18', 'Z19',\n",
       "       'Z20', 'Z21', 'Z22', 'Z23', 'Z24', 'Z25', 'Z26', 'Z27', 'Z28', 'Z29',\n",
       "       'Z30', 'Z31', 'Z32', 'direction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Above', 'Right', 'Below', 'Left'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.direction.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = []\n",
    "train_labels = []\n",
    "\n",
    "no_of_features = 96\n",
    "firstLine = True\n",
    "\n",
    "with open('Training.csv') as csvfile:\n",
    "    readCSV = csv.reader(csvfile, delimiter=',')\n",
    "    for row in readCSV:\n",
    "        if firstLine:\n",
    "            firstLine = False\n",
    "        else:\n",
    "            list = []\n",
    "            for i in range(0, no_of_features):\n",
    "                list.append(float(row[i]))\n",
    "\n",
    "            train_samples.append(np.array(list))\n",
    "            train_labels.append(row[no_of_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()\n",
    "transfomed_label = encoder.fit_transform(train_labels)\n",
    "\n",
    "train_samples = np.array(train_samples)\n",
    "train_labels = np.array(transfomed_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.18914771 0.18914771 0.18914771 ... 9.61061954 9.74230385 9.74230385]\n",
      " [0.17478207 0.17478207 0.17478207 ... 9.83089256 9.83089256 9.83089256]\n",
      " [0.25618741 0.25618741 0.25618741 ... 9.79258442 9.79976654 9.79976654]\n",
      " ...\n",
      " [0.1699935  0.1699935  0.1699935  ... 9.67526436 9.67526436 9.67526436]\n",
      " [0.18196489 0.18196489 0.18196489 ... 9.5866766  9.7039957  9.57949352]\n",
      " [0.20111908 0.20111908 0.20111908 ... 9.73512173 9.74948692 9.74948692]]\n",
      "[[1 0 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(train_samples)\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "scaled_train_samples = (scaler.fit_transform(train_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01562502 -0.01562502 -0.01562502 ...  0.37327367  0.24651197\n",
      "   0.23222686]\n",
      " [ 0.09375004  0.09375004  0.09375004 ...  0.06912679  0.45116391\n",
      "   0.44075872]\n",
      " [-0.03125001 -0.03125001 -0.03125001 ...  0.38248812  0.25581214\n",
      "   0.24170335]\n",
      " ...\n",
      " [ 0.51562508  0.51562508  0.51562508 ... -0.29032151 -0.42325599\n",
      "  -0.45023899]\n",
      " [-0.09374999 -0.09374999 -0.09374999 ...  0.31797223  0.19069612\n",
      "   0.17535282]\n",
      " [ 0.12500003  0.12500003  0.12500003 ...  0.23502375  0.6372081\n",
      "   0.63033005]]\n",
      "[[0 0 1 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]\n",
      " ...\n",
      " [0 0 1 0]\n",
      " [0 1 0 0]\n",
      " [0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "scaled_train_samples, train_labels = shuffle(scaled_train_samples, train_labels, random_state=0)\n",
    "print(scaled_train_samples)\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, input_shape=(96,), activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                6208      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 14,788\n",
      "Trainable params: 14,788\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "74/74 - 5s - loss: 1.2432 - accuracy: 0.4624 - val_loss: 0.9759 - val_accuracy: 0.7805\n",
      "Epoch 2/150\n",
      "74/74 - 0s - loss: 0.7875 - accuracy: 0.7360 - val_loss: 0.6554 - val_accuracy: 0.7805\n",
      "Epoch 3/150\n",
      "74/74 - 0s - loss: 0.5153 - accuracy: 0.8304 - val_loss: 0.4812 - val_accuracy: 0.8537\n",
      "Epoch 4/150\n",
      "74/74 - 0s - loss: 0.3512 - accuracy: 0.8865 - val_loss: 0.4249 - val_accuracy: 0.8537\n",
      "Epoch 5/150\n",
      "74/74 - 0s - loss: 0.2538 - accuracy: 0.9234 - val_loss: 0.3204 - val_accuracy: 0.9024\n",
      "Epoch 6/150\n",
      "74/74 - 0s - loss: 0.2068 - accuracy: 0.9302 - val_loss: 0.3808 - val_accuracy: 0.8537\n",
      "Epoch 7/150\n",
      "74/74 - 0s - loss: 0.1519 - accuracy: 0.9617 - val_loss: 0.3266 - val_accuracy: 0.8902\n",
      "Epoch 8/150\n",
      "74/74 - 0s - loss: 0.1393 - accuracy: 0.9590 - val_loss: 0.3201 - val_accuracy: 0.9146\n",
      "Epoch 9/150\n",
      "74/74 - 0s - loss: 0.0921 - accuracy: 0.9795 - val_loss: 0.3154 - val_accuracy: 0.9390\n",
      "Epoch 10/150\n",
      "74/74 - 0s - loss: 0.0682 - accuracy: 0.9863 - val_loss: 0.3517 - val_accuracy: 0.9024\n",
      "Epoch 11/150\n",
      "74/74 - 0s - loss: 0.0538 - accuracy: 0.9904 - val_loss: 0.3574 - val_accuracy: 0.9024\n",
      "Epoch 12/150\n",
      "74/74 - 0s - loss: 0.0366 - accuracy: 0.9973 - val_loss: 0.3369 - val_accuracy: 0.9268\n",
      "Epoch 13/150\n",
      "74/74 - 0s - loss: 0.0243 - accuracy: 0.9986 - val_loss: 0.3555 - val_accuracy: 0.9268\n",
      "Epoch 14/150\n",
      "74/74 - 0s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.3754 - val_accuracy: 0.9024\n",
      "Epoch 15/150\n",
      "74/74 - 0s - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.3649 - val_accuracy: 0.9146\n",
      "Epoch 16/150\n",
      "74/74 - 0s - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.3903 - val_accuracy: 0.9146\n",
      "Epoch 17/150\n",
      "74/74 - 0s - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.3713 - val_accuracy: 0.9390\n",
      "Epoch 18/150\n",
      "74/74 - 0s - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.3887 - val_accuracy: 0.9268\n",
      "Epoch 19/150\n",
      "74/74 - 0s - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.3997 - val_accuracy: 0.9268\n",
      "Epoch 20/150\n",
      "74/74 - 0s - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4207 - val_accuracy: 0.9146\n",
      "Epoch 21/150\n",
      "74/74 - 0s - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.9146\n",
      "Epoch 22/150\n",
      "74/74 - 0s - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4214 - val_accuracy: 0.9146\n",
      "Epoch 23/150\n",
      "74/74 - 0s - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4263 - val_accuracy: 0.9268\n",
      "Epoch 24/150\n",
      "74/74 - 0s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4445 - val_accuracy: 0.9268\n",
      "Epoch 25/150\n",
      "74/74 - 0s - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4411 - val_accuracy: 0.9268\n",
      "Epoch 26/150\n",
      "74/74 - 0s - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4568 - val_accuracy: 0.9146\n",
      "Epoch 27/150\n",
      "74/74 - 0s - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4578 - val_accuracy: 0.9268\n",
      "Epoch 28/150\n",
      "74/74 - 0s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4597 - val_accuracy: 0.9268\n",
      "Epoch 29/150\n",
      "74/74 - 0s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.9268\n",
      "Epoch 30/150\n",
      "74/74 - 0s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4666 - val_accuracy: 0.9268\n",
      "Epoch 31/150\n",
      "74/74 - 0s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4706 - val_accuracy: 0.9268\n",
      "Epoch 32/150\n",
      "74/74 - 0s - loss: 9.7853e-04 - accuracy: 1.0000 - val_loss: 0.4816 - val_accuracy: 0.9146\n",
      "Epoch 33/150\n",
      "74/74 - 0s - loss: 8.8159e-04 - accuracy: 1.0000 - val_loss: 0.4867 - val_accuracy: 0.9146\n",
      "Epoch 34/150\n",
      "74/74 - 0s - loss: 8.1241e-04 - accuracy: 1.0000 - val_loss: 0.4893 - val_accuracy: 0.9146\n",
      "Epoch 35/150\n",
      "74/74 - 0s - loss: 7.3418e-04 - accuracy: 1.0000 - val_loss: 0.4929 - val_accuracy: 0.9268\n",
      "Epoch 36/150\n",
      "74/74 - 0s - loss: 6.9859e-04 - accuracy: 1.0000 - val_loss: 0.5030 - val_accuracy: 0.9268\n",
      "Epoch 37/150\n",
      "74/74 - 0s - loss: 6.5789e-04 - accuracy: 1.0000 - val_loss: 0.4995 - val_accuracy: 0.9146\n",
      "Epoch 38/150\n",
      "74/74 - 0s - loss: 5.8494e-04 - accuracy: 1.0000 - val_loss: 0.5048 - val_accuracy: 0.9268\n",
      "Epoch 39/150\n",
      "74/74 - 0s - loss: 5.4520e-04 - accuracy: 1.0000 - val_loss: 0.5113 - val_accuracy: 0.9146\n",
      "Epoch 40/150\n",
      "74/74 - 0s - loss: 5.0925e-04 - accuracy: 1.0000 - val_loss: 0.5138 - val_accuracy: 0.9268\n",
      "Epoch 41/150\n",
      "74/74 - 0s - loss: 4.7288e-04 - accuracy: 1.0000 - val_loss: 0.5127 - val_accuracy: 0.9146\n",
      "Epoch 42/150\n",
      "74/74 - 0s - loss: 4.7326e-04 - accuracy: 1.0000 - val_loss: 0.5234 - val_accuracy: 0.9146\n",
      "Epoch 43/150\n",
      "74/74 - 0s - loss: 4.1342e-04 - accuracy: 1.0000 - val_loss: 0.5287 - val_accuracy: 0.9268\n",
      "Epoch 44/150\n",
      "74/74 - 0s - loss: 3.7700e-04 - accuracy: 1.0000 - val_loss: 0.5295 - val_accuracy: 0.9268\n",
      "Epoch 45/150\n",
      "74/74 - 0s - loss: 3.5667e-04 - accuracy: 1.0000 - val_loss: 0.5376 - val_accuracy: 0.9268\n",
      "Epoch 46/150\n",
      "74/74 - 0s - loss: 3.3016e-04 - accuracy: 1.0000 - val_loss: 0.5388 - val_accuracy: 0.9146\n",
      "Epoch 47/150\n",
      "74/74 - 0s - loss: 3.2905e-04 - accuracy: 1.0000 - val_loss: 0.5396 - val_accuracy: 0.9268\n",
      "Epoch 48/150\n",
      "74/74 - 0s - loss: 2.8974e-04 - accuracy: 1.0000 - val_loss: 0.5411 - val_accuracy: 0.9146\n",
      "Epoch 49/150\n",
      "74/74 - 0s - loss: 2.6365e-04 - accuracy: 1.0000 - val_loss: 0.5468 - val_accuracy: 0.9268\n",
      "Epoch 50/150\n",
      "74/74 - 0s - loss: 2.5458e-04 - accuracy: 1.0000 - val_loss: 0.5525 - val_accuracy: 0.9146\n",
      "Epoch 51/150\n",
      "74/74 - 0s - loss: 2.3769e-04 - accuracy: 1.0000 - val_loss: 0.5553 - val_accuracy: 0.9146\n",
      "Epoch 52/150\n",
      "74/74 - 0s - loss: 2.2827e-04 - accuracy: 1.0000 - val_loss: 0.5537 - val_accuracy: 0.9268\n",
      "Epoch 53/150\n",
      "74/74 - 0s - loss: 2.1022e-04 - accuracy: 1.0000 - val_loss: 0.5604 - val_accuracy: 0.9268\n",
      "Epoch 54/150\n",
      "74/74 - 0s - loss: 1.9744e-04 - accuracy: 1.0000 - val_loss: 0.5647 - val_accuracy: 0.9268\n",
      "Epoch 55/150\n",
      "74/74 - 0s - loss: 1.8420e-04 - accuracy: 1.0000 - val_loss: 0.5661 - val_accuracy: 0.9268\n",
      "Epoch 56/150\n",
      "74/74 - 0s - loss: 1.7828e-04 - accuracy: 1.0000 - val_loss: 0.5717 - val_accuracy: 0.9268\n",
      "Epoch 57/150\n",
      "74/74 - 0s - loss: 1.6393e-04 - accuracy: 1.0000 - val_loss: 0.5742 - val_accuracy: 0.9268\n",
      "Epoch 58/150\n",
      "74/74 - 0s - loss: 1.5738e-04 - accuracy: 1.0000 - val_loss: 0.5803 - val_accuracy: 0.9268\n",
      "Epoch 59/150\n",
      "74/74 - 0s - loss: 1.4875e-04 - accuracy: 1.0000 - val_loss: 0.5763 - val_accuracy: 0.9268\n",
      "Epoch 60/150\n",
      "74/74 - 0s - loss: 1.3737e-04 - accuracy: 1.0000 - val_loss: 0.5809 - val_accuracy: 0.9268\n",
      "Epoch 61/150\n",
      "74/74 - 0s - loss: 1.3737e-04 - accuracy: 1.0000 - val_loss: 0.5853 - val_accuracy: 0.9268\n",
      "Epoch 62/150\n",
      "74/74 - 0s - loss: 1.2418e-04 - accuracy: 1.0000 - val_loss: 0.5834 - val_accuracy: 0.9268\n",
      "Epoch 63/150\n",
      "74/74 - 0s - loss: 1.1704e-04 - accuracy: 1.0000 - val_loss: 0.5892 - val_accuracy: 0.9268\n",
      "Epoch 64/150\n",
      "74/74 - 0s - loss: 1.1285e-04 - accuracy: 1.0000 - val_loss: 0.5972 - val_accuracy: 0.9268\n",
      "Epoch 65/150\n",
      "74/74 - 0s - loss: 1.0488e-04 - accuracy: 1.0000 - val_loss: 0.6013 - val_accuracy: 0.9268\n",
      "Epoch 66/150\n",
      "74/74 - 0s - loss: 1.0060e-04 - accuracy: 1.0000 - val_loss: 0.6052 - val_accuracy: 0.9268\n",
      "Epoch 67/150\n",
      "74/74 - 0s - loss: 9.3738e-05 - accuracy: 1.0000 - val_loss: 0.6071 - val_accuracy: 0.9268\n",
      "Epoch 68/150\n",
      "74/74 - 0s - loss: 8.8731e-05 - accuracy: 1.0000 - val_loss: 0.6079 - val_accuracy: 0.9268\n",
      "Epoch 69/150\n",
      "74/74 - 0s - loss: 8.5510e-05 - accuracy: 1.0000 - val_loss: 0.6145 - val_accuracy: 0.9268\n",
      "Epoch 70/150\n",
      "74/74 - 0s - loss: 8.1064e-05 - accuracy: 1.0000 - val_loss: 0.6150 - val_accuracy: 0.9268\n",
      "Epoch 71/150\n",
      "74/74 - 0s - loss: 7.6266e-05 - accuracy: 1.0000 - val_loss: 0.6167 - val_accuracy: 0.9268\n",
      "Epoch 72/150\n",
      "74/74 - 0s - loss: 7.3091e-05 - accuracy: 1.0000 - val_loss: 0.6226 - val_accuracy: 0.9268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/150\n",
      "74/74 - 0s - loss: 6.8855e-05 - accuracy: 1.0000 - val_loss: 0.6219 - val_accuracy: 0.9268\n",
      "Epoch 74/150\n",
      "74/74 - 0s - loss: 6.6107e-05 - accuracy: 1.0000 - val_loss: 0.6211 - val_accuracy: 0.9268\n",
      "Epoch 75/150\n",
      "74/74 - 0s - loss: 6.3009e-05 - accuracy: 1.0000 - val_loss: 0.6312 - val_accuracy: 0.9268\n",
      "Epoch 76/150\n",
      "74/74 - 0s - loss: 5.9843e-05 - accuracy: 1.0000 - val_loss: 0.6317 - val_accuracy: 0.9268\n",
      "Epoch 77/150\n",
      "74/74 - 0s - loss: 5.6277e-05 - accuracy: 1.0000 - val_loss: 0.6330 - val_accuracy: 0.9268\n",
      "Epoch 78/150\n",
      "74/74 - 0s - loss: 5.3695e-05 - accuracy: 1.0000 - val_loss: 0.6364 - val_accuracy: 0.9268\n",
      "Epoch 79/150\n",
      "74/74 - 0s - loss: 5.1653e-05 - accuracy: 1.0000 - val_loss: 0.6397 - val_accuracy: 0.9268\n",
      "Epoch 80/150\n",
      "74/74 - 0s - loss: 4.8119e-05 - accuracy: 1.0000 - val_loss: 0.6422 - val_accuracy: 0.9268\n",
      "Epoch 81/150\n",
      "74/74 - 0s - loss: 4.6065e-05 - accuracy: 1.0000 - val_loss: 0.6455 - val_accuracy: 0.9268\n",
      "Epoch 82/150\n",
      "74/74 - 0s - loss: 4.4025e-05 - accuracy: 1.0000 - val_loss: 0.6449 - val_accuracy: 0.9268\n",
      "Epoch 83/150\n",
      "74/74 - 0s - loss: 4.1841e-05 - accuracy: 1.0000 - val_loss: 0.6511 - val_accuracy: 0.9268\n",
      "Epoch 84/150\n",
      "74/74 - 0s - loss: 3.9717e-05 - accuracy: 1.0000 - val_loss: 0.6521 - val_accuracy: 0.9268\n",
      "Epoch 85/150\n",
      "74/74 - 0s - loss: 3.8194e-05 - accuracy: 1.0000 - val_loss: 0.6538 - val_accuracy: 0.9268\n",
      "Epoch 86/150\n",
      "74/74 - 0s - loss: 3.7260e-05 - accuracy: 1.0000 - val_loss: 0.6615 - val_accuracy: 0.9268\n",
      "Epoch 87/150\n",
      "74/74 - 0s - loss: 3.4118e-05 - accuracy: 1.0000 - val_loss: 0.6677 - val_accuracy: 0.9268\n",
      "Epoch 88/150\n",
      "74/74 - 0s - loss: 3.2464e-05 - accuracy: 1.0000 - val_loss: 0.6684 - val_accuracy: 0.9268\n",
      "Epoch 89/150\n",
      "74/74 - 0s - loss: 3.1030e-05 - accuracy: 1.0000 - val_loss: 0.6717 - val_accuracy: 0.9268\n",
      "Epoch 90/150\n",
      "74/74 - 0s - loss: 2.9377e-05 - accuracy: 1.0000 - val_loss: 0.6728 - val_accuracy: 0.9268\n",
      "Epoch 91/150\n",
      "74/74 - 0s - loss: 2.8044e-05 - accuracy: 1.0000 - val_loss: 0.6729 - val_accuracy: 0.9268\n",
      "Epoch 92/150\n",
      "74/74 - 0s - loss: 2.6800e-05 - accuracy: 1.0000 - val_loss: 0.6743 - val_accuracy: 0.9268\n",
      "Epoch 93/150\n",
      "74/74 - 0s - loss: 2.5544e-05 - accuracy: 1.0000 - val_loss: 0.6777 - val_accuracy: 0.9268\n",
      "Epoch 94/150\n",
      "74/74 - 0s - loss: 2.4291e-05 - accuracy: 1.0000 - val_loss: 0.6781 - val_accuracy: 0.9268\n",
      "Epoch 95/150\n",
      "74/74 - 0s - loss: 2.3171e-05 - accuracy: 1.0000 - val_loss: 0.6820 - val_accuracy: 0.9268\n",
      "Epoch 96/150\n",
      "74/74 - 0s - loss: 2.1963e-05 - accuracy: 1.0000 - val_loss: 0.6846 - val_accuracy: 0.9268\n",
      "Epoch 97/150\n",
      "74/74 - 0s - loss: 2.1335e-05 - accuracy: 1.0000 - val_loss: 0.6858 - val_accuracy: 0.9268\n",
      "Epoch 98/150\n",
      "74/74 - 0s - loss: 2.0085e-05 - accuracy: 1.0000 - val_loss: 0.6912 - val_accuracy: 0.9268\n",
      "Epoch 99/150\n",
      "74/74 - 0s - loss: 1.9288e-05 - accuracy: 1.0000 - val_loss: 0.6934 - val_accuracy: 0.9146\n",
      "Epoch 100/150\n",
      "74/74 - 0s - loss: 1.9106e-05 - accuracy: 1.0000 - val_loss: 0.7026 - val_accuracy: 0.9268\n",
      "Epoch 101/150\n",
      "74/74 - 0s - loss: 1.7399e-05 - accuracy: 1.0000 - val_loss: 0.7019 - val_accuracy: 0.9268\n",
      "Epoch 102/150\n",
      "74/74 - 0s - loss: 1.6474e-05 - accuracy: 1.0000 - val_loss: 0.7036 - val_accuracy: 0.9268\n",
      "Epoch 103/150\n",
      "74/74 - 0s - loss: 1.5784e-05 - accuracy: 1.0000 - val_loss: 0.7064 - val_accuracy: 0.9268\n",
      "Epoch 104/150\n",
      "74/74 - 0s - loss: 1.4971e-05 - accuracy: 1.0000 - val_loss: 0.7081 - val_accuracy: 0.9268\n",
      "Epoch 105/150\n",
      "74/74 - 0s - loss: 1.4318e-05 - accuracy: 1.0000 - val_loss: 0.7113 - val_accuracy: 0.9268\n",
      "Epoch 106/150\n",
      "74/74 - 0s - loss: 1.3800e-05 - accuracy: 1.0000 - val_loss: 0.7154 - val_accuracy: 0.9146\n",
      "Epoch 107/150\n",
      "74/74 - 0s - loss: 1.3115e-05 - accuracy: 1.0000 - val_loss: 0.7154 - val_accuracy: 0.9268\n",
      "Epoch 108/150\n",
      "74/74 - 0s - loss: 1.2511e-05 - accuracy: 1.0000 - val_loss: 0.7173 - val_accuracy: 0.9268\n",
      "Epoch 109/150\n",
      "74/74 - 0s - loss: 1.2611e-05 - accuracy: 1.0000 - val_loss: 0.7172 - val_accuracy: 0.9268\n",
      "Epoch 110/150\n",
      "74/74 - 0s - loss: 1.1683e-05 - accuracy: 1.0000 - val_loss: 0.7235 - val_accuracy: 0.9268\n",
      "Epoch 111/150\n",
      "74/74 - 0s - loss: 1.1001e-05 - accuracy: 1.0000 - val_loss: 0.7264 - val_accuracy: 0.9268\n",
      "Epoch 112/150\n",
      "74/74 - 0s - loss: 1.0358e-05 - accuracy: 1.0000 - val_loss: 0.7261 - val_accuracy: 0.9268\n",
      "Epoch 113/150\n",
      "74/74 - 0s - loss: 9.8719e-06 - accuracy: 1.0000 - val_loss: 0.7318 - val_accuracy: 0.9268\n",
      "Epoch 114/150\n",
      "74/74 - 0s - loss: 9.4143e-06 - accuracy: 1.0000 - val_loss: 0.7311 - val_accuracy: 0.9268\n",
      "Epoch 115/150\n",
      "74/74 - 0s - loss: 9.0380e-06 - accuracy: 1.0000 - val_loss: 0.7355 - val_accuracy: 0.9268\n",
      "Epoch 116/150\n",
      "74/74 - 0s - loss: 8.6365e-06 - accuracy: 1.0000 - val_loss: 0.7335 - val_accuracy: 0.9146\n",
      "Epoch 117/150\n",
      "74/74 - 0s - loss: 8.2799e-06 - accuracy: 1.0000 - val_loss: 0.7382 - val_accuracy: 0.9268\n",
      "Epoch 118/150\n",
      "74/74 - 0s - loss: 8.1558e-06 - accuracy: 1.0000 - val_loss: 0.7418 - val_accuracy: 0.9146\n",
      "Epoch 119/150\n",
      "74/74 - 0s - loss: 7.5819e-06 - accuracy: 1.0000 - val_loss: 0.7415 - val_accuracy: 0.9146\n",
      "Epoch 120/150\n",
      "74/74 - 0s - loss: 7.2035e-06 - accuracy: 1.0000 - val_loss: 0.7444 - val_accuracy: 0.9146\n",
      "Epoch 121/150\n",
      "74/74 - 0s - loss: 7.0099e-06 - accuracy: 1.0000 - val_loss: 0.7488 - val_accuracy: 0.9268\n",
      "Epoch 122/150\n",
      "74/74 - 0s - loss: 6.7097e-06 - accuracy: 1.0000 - val_loss: 0.7581 - val_accuracy: 0.9268\n",
      "Epoch 123/150\n",
      "74/74 - 0s - loss: 6.2943e-06 - accuracy: 1.0000 - val_loss: 0.7599 - val_accuracy: 0.9268\n",
      "Epoch 124/150\n",
      "74/74 - 0s - loss: 6.0212e-06 - accuracy: 1.0000 - val_loss: 0.7588 - val_accuracy: 0.9268\n",
      "Epoch 125/150\n",
      "74/74 - 0s - loss: 5.8015e-06 - accuracy: 1.0000 - val_loss: 0.7601 - val_accuracy: 0.9268\n",
      "Epoch 126/150\n",
      "74/74 - 0s - loss: 5.4969e-06 - accuracy: 1.0000 - val_loss: 0.7621 - val_accuracy: 0.9268\n",
      "Epoch 127/150\n",
      "74/74 - 0s - loss: 5.2453e-06 - accuracy: 1.0000 - val_loss: 0.7642 - val_accuracy: 0.9268\n",
      "Epoch 128/150\n",
      "74/74 - 0s - loss: 5.0750e-06 - accuracy: 1.0000 - val_loss: 0.7676 - val_accuracy: 0.9268\n",
      "Epoch 129/150\n",
      "74/74 - 0s - loss: 4.8358e-06 - accuracy: 1.0000 - val_loss: 0.7688 - val_accuracy: 0.9268\n",
      "Epoch 130/150\n",
      "74/74 - 0s - loss: 4.6339e-06 - accuracy: 1.0000 - val_loss: 0.7698 - val_accuracy: 0.9268\n",
      "Epoch 131/150\n",
      "74/74 - 0s - loss: 4.4273e-06 - accuracy: 1.0000 - val_loss: 0.7737 - val_accuracy: 0.9146\n",
      "Epoch 132/150\n",
      "74/74 - 0s - loss: 4.2615e-06 - accuracy: 1.0000 - val_loss: 0.7771 - val_accuracy: 0.9146\n",
      "Epoch 133/150\n",
      "74/74 - 0s - loss: 4.1958e-06 - accuracy: 1.0000 - val_loss: 0.7808 - val_accuracy: 0.9146\n",
      "Epoch 134/150\n",
      "74/74 - 0s - loss: 3.8649e-06 - accuracy: 1.0000 - val_loss: 0.7817 - val_accuracy: 0.9146\n",
      "Epoch 135/150\n",
      "74/74 - 0s - loss: 3.7336e-06 - accuracy: 1.0000 - val_loss: 0.7852 - val_accuracy: 0.9268\n",
      "Epoch 136/150\n",
      "74/74 - 0s - loss: 3.5736e-06 - accuracy: 1.0000 - val_loss: 0.7858 - val_accuracy: 0.9146\n",
      "Epoch 137/150\n",
      "74/74 - 0s - loss: 3.4024e-06 - accuracy: 1.0000 - val_loss: 0.7877 - val_accuracy: 0.9146\n",
      "Epoch 138/150\n",
      "74/74 - 0s - loss: 3.2675e-06 - accuracy: 1.0000 - val_loss: 0.7903 - val_accuracy: 0.9146\n",
      "Epoch 139/150\n",
      "74/74 - 0s - loss: 3.1206e-06 - accuracy: 1.0000 - val_loss: 0.7893 - val_accuracy: 0.9146\n",
      "Epoch 140/150\n",
      "74/74 - 0s - loss: 3.0122e-06 - accuracy: 1.0000 - val_loss: 0.7965 - val_accuracy: 0.9146\n",
      "Epoch 141/150\n",
      "74/74 - 0s - loss: 2.8747e-06 - accuracy: 1.0000 - val_loss: 0.7957 - val_accuracy: 0.9146\n",
      "Epoch 142/150\n",
      "74/74 - 0s - loss: 2.7292e-06 - accuracy: 1.0000 - val_loss: 0.7992 - val_accuracy: 0.9146\n",
      "Epoch 143/150\n",
      "74/74 - 0s - loss: 2.6289e-06 - accuracy: 1.0000 - val_loss: 0.8002 - val_accuracy: 0.9146\n",
      "Epoch 144/150\n",
      "74/74 - 0s - loss: 2.5076e-06 - accuracy: 1.0000 - val_loss: 0.8009 - val_accuracy: 0.9146\n",
      "Epoch 145/150\n",
      "74/74 - 0s - loss: 2.4122e-06 - accuracy: 1.0000 - val_loss: 0.8051 - val_accuracy: 0.9146\n",
      "Epoch 146/150\n",
      "74/74 - 0s - loss: 2.3046e-06 - accuracy: 1.0000 - val_loss: 0.8106 - val_accuracy: 0.9146\n",
      "Epoch 147/150\n",
      "74/74 - 0s - loss: 2.2110e-06 - accuracy: 1.0000 - val_loss: 0.8157 - val_accuracy: 0.9146\n",
      "Epoch 148/150\n",
      "74/74 - 0s - loss: 2.1260e-06 - accuracy: 1.0000 - val_loss: 0.8144 - val_accuracy: 0.9146\n",
      "Epoch 149/150\n",
      "74/74 - 0s - loss: 2.0280e-06 - accuracy: 1.0000 - val_loss: 0.8114 - val_accuracy: 0.9146\n",
      "Epoch 150/150\n",
      "74/74 - 0s - loss: 1.9781e-06 - accuracy: 1.0000 - val_loss: 0.8211 - val_accuracy: 0.9146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xce2e18c550>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "model.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(scaled_train_samples, train_labels, validation_split = 0.1, batch_size=10, epochs=150, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 1ms/step - loss: 0.0828 - accuracy: 0.9914\n",
      "Accuracy: 99.14\n"
     ]
    }
   ],
   "source": [
    "_,accuracy = model.evaluate(scaled_train_samples,train_labels)\n",
    "print('Accuracy: %.2f' %(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is about the values of x,y,z axes with 'Direction' as the target variable. The predicting labels are X1, X2,...X32 and likewise Y1,Y2 ....Y32 and Z1,Z2,Z3,......Z32\n",
    "\n",
    "We process the csv data to array datatype and fit it into MultiLayer Perceptron model using keras API. \n",
    "Training_samples array has predicting variables and train_labels has 4 directions encoded( for 'RIGHT', [0 1 0 0]).\n",
    "\n",
    "We create keras model with 5 layers:\n",
    "1. Input layer : 96\n",
    "2. 1st hidden layer: 64, activation: relu\n",
    "3. 2nd hidden layer: 64, activation: relu\n",
    "4. 3rd hidden layer: 64, activation: relu\n",
    "5. Output layer: 4, activation: softmax\n",
    "\n",
    "We see that for 150 epochs, adam optimizer, we get accuracy of 99.38%. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
